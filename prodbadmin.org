* Installing the oracle binaries
** Understanding the OFA
OFA: Optimal Flexible architecture
#+CAPTION: Optimal flexible architecture
#+NAME: FIG1-1
[[./pic/directory of database.png]]

*** Oracle Inventory Directory
The Oracle inventory directory stores the inventory of Oracle software installed on the server.When you first install oracle, the installer checks where there is an existing OFA compliant directory structure in the format /u[01-09/app, if such a directory exist then installer creats a directory such as
/u01/app/oraInventory
If the $oracle\_base varible is defined for oracle system user, then the installer creates a directory of the location of the oracle inventory as follows:
$oracle\_base/../oraInventory
If the installer doesn't find a recognizable OFA-compliant directory or $oracle\_base varible,then the location for oracle Inventory is created under the HOME directory of the oracle user. For instance, if the HOME directory is /home/oracle, then the location of the Oracle Inventory is
/home/oracle/oraInventory
*** Oracle Base Directory
The oracle base directory is the topmost directory of oracle software installation. You can install one or more versions of software beneath this directory. The OFA standard for the oracle base directory is as follows:
/<mount-point>/app/<software owner>
Typical names for mount-point name include /u01, /ora01, /oracle and /oracle01. You can name the mount point according to what ever your standard is for your enviroment.
The software owner is typically named oracle. This is the user you use to install the Oracle software(binaries)
*** Oracle Home Directory
<ORACLE\_BASE>/product/<version>/<install_name>
<install\_name> include db\_1, devdb1, test2...
If you don't want to have a test database installed on the same machine, you can safely drop the <install\_name>.
*** Oracle Network Files Directory
/ORACLE\_HOME/network/admin
usually the tnsname.ora and listener.ora files are included in the directory
*** Automatic Diagnostic Repository
ORACLE\_BASE/diag/rdbms/lower(db\_unique\_name)/instance\_name
** Installing Oracle
*** Creating the OS Groups and Users
--------------------------------------------------------------------------------
OS Group  |Database System Previlege  | Authorized Operations | Where referenced
--------------------------------------------------------------------------------
......
sudo groupadd <group-name>
sudo useradd -g <group-name> -G <group-name>,<group-name> <username>
*** Ensure the OS is adequatly configured
+ memory and swap space
+ system architecture
+ free space disk
+ operating system and version
+ operating system software
*** Obtain the Oracle database software 
*** unzip the software
*** Creating oraInst.loc File

** /!!!!my installation!!!!/
the procedure of the installation is added to bookmarks in google-chrome, you can reference to it and centOS will be a OS more suitable to OS installation.
** Implimenting a Database
There are two ways to create a database: one is using dbca the other is run "create database" from SQL*Plus
*** Setting OS varibles
1. ORACLE_HOME
2. ORACLE_SSID
3. LD_LIBRARY_PATH
4. PATH
ORACLE_HOME defines where the initial file is and where the executable binary file is, in linux, they are $ORACLE_HOME/dbs and $ORACLE_HOME/bin.
**** A Manually Intensive Approach
export ORACLE_HOME="/home/wafflepie/oracle/app/wafflepie/product/12.1.0/dbhome_1"
export PATH="$ORACLE_HOME/bin:$PATH"
export LD_LIBRARY_PATH="/usr/lib:$ORACLE_HOME/lib/"
export ORACLE_SID="o12c"
For now, the new install oracle has no ORACLE_SID, I think it's because i choose to install the software only without choosing to install a database.
**** Oracle's Approach to Setting OS Varibles
This approach relies on two files: oratab & oraenv
***** Understanding oratab
The oratab file are located in /etc in linux system, it is used by oraenv to set system varibles and used by program like dbstart, dbshut to start or shut database when system reboots.
oraenv, dbstart and dbshut are all located in $ORACLE_HOME/bin folder.
***** Using oraenv
The oraenv set OS varibles by inspecting oratab file, it can be executed silently and it can be written into .bashrc, so everytime the system boots, it will be executed.
NOTICE: To run oraenv in commandline, you need to place a blank(' ') instead a slash('/') between dot and oraenv, eg:". oraenv".
**** My Approach to Setting OS Varibles
A oraset script is given in the book, I think I will not need to use it because I only need to administrate one database.You may find it in page 34.
** Creating a Database
1. Set OS variables
2. Configure the initialization file
3. Create the required directory
4. Create the database
5. Create a dataase directory
*** Step1: Set OS varibles
As previous mentioned
*** Step2: Configure the Initialization File
Two types of configuration file:
1. Server parameter binary file(spfile)
2. init.ora text file

Oracle recomand to use spfile, because it is easy to change in oracle sqlplus and you can use remote-client SQL session to start the database without requiring a local initialization file.
Using init.ora text file also has advantages, you can modify it using OS editor and you can comment in the file for historic reference, besides if you have to use spfile, you can generate one from init.ora using create SPFILE from PFILE statement.
The spfile and init.ora file are located in $ORACLE_HOME/dbs folder.
The most important thing about the initialization file should be the default order the oracle look for:
spfile<SID>.ora
spfile.ora
init<SID>.ora
*** Step3: Create the Required Directory
Create control file directory and redo file directory. The place is arbitrary like /u01/dbfile/o12c/,/u01/oraredo/o12c.
The control file looks like control01.ctl. It ends up with ctl.
*** Step4: Create the Database
The credb.sql file is an example to create database.
From the script the following file are created:
1. DATAFILE 500M
2. UNDOTABLESPACE THIS IS LARGER THAN DATAFILE
3. SYSAUX DATAFILE SAME AS DATAFILE
4. TEMPORARY FILE SAME AS DATAFILE
5. USER DATAFILE 20M
6. LOGFILE 3GROUP REDO LOGFILE TOTAL 150M

NOTICE:In the credb.sql, the system file has a description about the extend management, it is specified as LOCAL, this means tablespaces you created must be managed locally not dictionary-managed. If you try to create a dictionary-managed tablespace, oracle will throw out an error.
*** Step5: Create a Data Dictionary
run catalog.sql and catproc.sql in $ORACLE_HOME/rdbms/admin directory. Before this you can spool out a file to check if something unexpected happened before.

** Configuring and Implementing Listener
*** Manually Configuring a Listener
The configure file is located in $ORACLE_HOME/network/admin directory
<LISTENERNAME>=
(
    DISCRIPTION_LIST=
    (
	DISCRIPTION=
	(
	    ADDRESS_LIST=
	    (
	        ADDRESS=
		(
		    (PROTOCOL=<TCP>)(HOST=<HOST_NAME>)(PORT=<1521>)
	        )
	    )
	)
    )
)
dynamic registration
do not specify the SID_LIST_<LISTENERNAME> in the tns.ora file
static registration
specify the SID_LIST_<LISTENERNAME> in the tns.ora file
SID_LIST_LISTENER
(
    SID_LIST=
    (
        SID_DESC=
	(
	    (GLOBAL_DBNAME=<o12c>)
	    (ORACLE_HOME=<$ORACLE_HOME>)
	    (SID_NAME=<o12c>)
	)
    )

)
after you finish the listener configuration file, you can start the listener by run command 'lsnrctl start'.
*** Using Net Configuration Assistant
Run 'netca'
You can use netca.rsp file for a silent run.
netca -silent - responsefile <path/to/netca.rsp>
***  Connecting a Database through the network
direct connect to the remote database without settings
sql user/pass@'server:port/service_name'
You need username,password, server ip, port number and service_name(SID).
Also you can use local naming method to connect, this relies on $ORACLE_HOME/network/admin/tnsname.ora file. Typically the file looks like this:
<SERVICE_NAME>=
(
    DESCRIPTION=
    ( 
        ADDRESS=(PROTOCOL=<TCP>)(HOST=<HOSTNAME>)(PORT=<1521>)
	CONNECT_DATA=(SERVICE_NAME=<SERVICE_NAME>)
    )
)
After setting the file, you can connect to the server by running 'sqlplus system/foo@<SERVICE_NAME>'. This method requires you have a local tnsname.ora file.
*** Creating a Passwork File
1. use orapwd utility to generate a password file

In linux environment:
+ cd $ORACLE_HOME/dbs
+ orapwd file=orapw<ORACLE_SID> password=<SYS password>
2. set the initialization parameter REMOTE_LOGIN_PASSWORD to EXCLUSIVE
+ alter system set remote_login_passwordfile='EXCLUSIVE' scope=spfile;
You need to restart the instance to make previous changes take effects. You can add user to passwd file by grant command:
+ grand sysdba to someuser;
When you add someuser to the passwd file, the user can connect to the server as sys*
+ sqlplus <database connection string> as sys*
** Starting and Stop Database
*** Understanding OS Authentication
OS authentication means if you can log into OS via an OS authentication account, you can access the database without giving a correct password.
+ sqlplus anyname/anypwd as sysdba
*** Starting Database 
+ sqlplus / as sysdba
+ SQL>startup
For the prior command work, you need either an spfile or init.ora file in $ORACLE_HOME/dbs directory.
The startup invoke 3 steps:
+ Starting the instance
+ Mounting the database
+ Opening the database
The above 3 steps can be executed seprately:
+ SQL>start nomount
+ SQL>alter database mount
+ SQL>alter database open
The start up scheme can be described by the following picture:
[[./pic/startupscheme.png]]
#+CAPTION:Phases of Oracle startup
#+NAME:FIG2-2:Phases of Oracle startup
*** Stopping Database
shutdown [parameters]
parameters:
NORMAL
TRANSITIONAL LOCAL
TRANSITIONAL
IMMEDIATE
ABORT
*** DATABASE AND INSTANCE
After 'alter database close ', you can not 'alter database open'
successfully, because a instance can only associate with one database
for its whole life.
*** Using dbca to create database
graphical mode 
silent mode:
1.. locate dhcp.rsp file
2. make a copy of dhcp.rsp file
3. modify the copy of dhcp.rsp file for your enviroment
4. run dbca utility in silent mode: dbca -silent -responseFile
/path/to/resopnsefile.
*** Dropping database
SQL> shutdown immediate;
SQL> start mount exclusive restrict;
SQL> drop database;
drop database command doesn't remove old archieve redo log files. You
must remove them manully or use RMAN to remove old archive and redo
logs.
** How many databases on a server
**** one server per database
#+CAPTION: one server per database
#+NAME: Fig2-3
[[./pic/one server per database.png]]
**** multiple databases sharing one set of oracle binaries on one
server

#+CAPTION: multi database share one set of oracle binaries on a server.png
#+NAME: Fig2-4
[[./pic/multi database share one set of oracle binaries on a server.png]]

If you need different versions of oracle database you need to have
multiple ORACLE HOME to house those installations.
**** one database used by multiple apps and many users
#+CAPTION: one database used by multiple applications and users
#+NAME: Fig2-5
[[./pic/one database used by multiple apps and users.png]]

If you don't have enough computational resources to have multiple
databases on one server, you can try using one database to host
multiple applications
**** one container database with multiple pluggable databases
#+CAPTION:
#+NAME: Fig2-6
[[./pic/one container database with multiple pluggable databases.png]]

In oracle 12c you have this option to have pluggable databases in one
container database.
** Understanding Oracle Architecture
#+CAPTION: Oracle database architecture
#+NAME: Fig2-7
[[./pic/oracle database architecture.png]]

* TABLESPACES AND DATA FILES
Tablespace is not just a space of tables, it is a logical container that
allows you to manage groups of data files, the physical files on disks
that consume space. Once a table space is created you can then create
databases objects within table spaces, which results in space
allocated on disks in the associated data files.
Tablespace is logical, it only exists when database is up and running.
Data files are physical existences, they persists wheather database is
open or closed.
database contain several tablespaces, one tablespaces contain many
tables, one table can belong to only one tablespace.
Objects are owner by creaters and created within tablespaces. A object
is instanciated as a segment. A segment consists extents of space
within tablespace. A extent consists of a set of database blocks.
[[./pic/relationship of logical storage objects and physical objects.png]]
** Understanding the first five
SYSTEM:should be owned by sys role only when database is created

SYSAUX:used for oracle tools usage

TMP :  if memory is not enough or need a temparay place to storge data

UNDO:  used for undo operation or instance crash or flashback
things like that.

USERS: not necessary, but often used as a permanent tablespace for
user.
** Table Operation
*** Creating tablespaces
command: create tablespace

parameter: usually you need only two parameters, besides datafile path
and size, which are locally managed extent allocation and automatic
segment space management.

eg: create tablespace tools

datafile /u01/dbfile/o12c/tools01.dbf

size 100M

extent management local

uniform size 128k

segment space management auto;



* DATA PUMP
** DATA PUMP ARCHITECTURE
- process
  - master process: ora_dwNN_<SID>
  - work process:
  - status table created: SYS_<OPERATION>_<JOB_MODE>_NN
    - operation: export | import
    - job_mode: full|schema|table|tablespace|transportable
      - job table dropped when job terminated
      - job table retained if job terminated abnormally and restore when job restarted.
- dp directory
  - default directory defined in directory object named DATA_PUMP_DIR
- LOG DIRECTORY
  - default: $ORACLE_HOME/rdbms/log
#+CAPTION: export architecture
#+NAME: figure-13.1
[[./pic/exp_architecture.png]]
#+CAPTION: import architecture
#+NAME: figure-13.2
[[./pic/imp_architecture.png]]
** get started
- do NOT use default directory for dp_directory
  - it will make $ORACLE_HOME directory very large
*** process
**** manually
- create default dp_directory
- grant authorization to user
- run expdp
  - if dumpfile already exists then oracle will throw an error.
**** use parameter file
- parameter file: exp.par
- run expdp exp.par

*** mode
**** Exporting and Importing the whole database
- priviledge: DBA or DATAPUMP_EXP_FULL_DATABASE role granted
- priviledge: DBA or DATAPUMP_IMP_FULL_DATABASE role granted
- parameter: full=Y
***** export CAUTIONS
- SYS scheme are never exported by datapump
- index are not exported but DDL that contains the SQL required to recreate index are exported

***** import CAUTIONS
- import will try to create tablespace and directory or dfatafiles, if any has exists then import will fail.
- if any user has already, import will fail to recreate the user, it will move on to the next task
- import will make sys and system user has the same password with the original database, so you'd better to change the password of SYS and SYSTEM account to distinguish the new database from the original one
- not only SYS and SYSTEM user, other user will have the same password with the original ones, so maybe it's better to change the password
- after each table is created, index table will be created
- table will be recreated if the same table already exist and contain data, you can specify the method to deal with the problem that the object already exists.
**** scheme level
- this is the default level
- you can import scheme from dmp file that obtained from full export
**** table level
- tell impdp or expdp which table you want to operates
- you can import table from dmp file that obtained from full or schema export
**** teblespace level
- specifiy the tablespace name while expdp or impdp
***** tablespace CAUTION
- it does NOT try to recreate tablespace themselves.
*** Transferring DATA
- network
- copying data files
- external tables
**** network method
**** copying data files method
- create corresponding user on dest database
create user &&username identified by &&user_pwd;
grant connect,resource to &&user;
alter user &&user default tablespace &&tablespace_name;
- create database linke to remote source database and connect to the source database with a dba user
create database link &&linkname
connect to &&sourcename identified by &&username
- CAUTIONS
the network link created here is very important
using 'xx:1522/xxxx';
- create a log directory in dest database
create or replace directory &&directory_name as '&&path/to/log'
- import database
*** Features for Manipulating Stroage
**** Exporting Tablespace Metadata
- sometimes you need to build an environment without data, you can use the metadata to build the environment
  - e.g.:expdp mv_maint/foo directory=dp_dir dumpfile=inv.dmp full=y include=tablespace
  - then you can import the DDL data into sql file, so you can modify the DDL file according to your needs or just execute it
    - e.g.:impdp mv_maint/foo directory=dp_dir dumpfile=inv.dmp sqlfile=tbsp.sql
**** Specifying Different Data File Paths and Names
- use REMAP_DATAFILE parameter
  - remap_datafile="'<source_file_path_and_name>':'<dest_file_path_and_name>'"
**** Importing into a Tablespace Different from the Original
- keyword: remap_schema, remap_tablespace
  - remap_schema
    - usage:remap_schema=<source_schema_name>:<dest_schema_name>
  - remap_tablespace
    - usage: remap=<source_tablespace_name>:<dest_tablespace_name>
**** Change the Size of Data Files
- keyword
  - transform
    - usage: transform=pctspace:<number of percentage>
**** Change Segment and Storage Attributs
- keyword: TRANSFORM
*** Filtering Data and Objects
- keyword: QUERY, SAMPLE, CONTENT, EXCLUDE, INCLUDE
**** Specifying a Query
- keyword: QUERY
  - usage: QUERY=[schema.][table_name:] query_clause
**** Exporting a Percentage of the Data
- keyword: SAMPLE
  - usage: [[schema_name.]table_name:]sample_percent
  - e.g.:expde mv_maint/foo directory=dp_dir tables=inv sample=10 dumpfile=inv.dmp
  - e.g.:expdp mv_maint/foo directory=dp_dir tables=inv,reg sample=reg:30 dumpfile=inv.dmp
- CAUTIONS
The SAMPLE parameter is only valid for exports
**** Excluding Objects from the Export File
- keyword: EXCLUDE
  - usage: EXCLUDE = object_type[:name_clause][,...]
  - you can NOT exclude a include object, for example, you can't exclude schema when export in schema mode
***** Excluding Statistics
- keyword: EXCLUDE=STATISTICS
**** Including Only Specific Objects in an Export File
- keyword: INCLUDE
  - e.g.: INCLUDE=procedure,function
  - e.g.: INCLUDE=function:\"=\'IS_DATE\'\"
**** Exporting Table, Index, Constraint, and Trigger DDL
- e.g:expdp mv_maint/foo directory=dp_dir dumpfile=ddl.dmp content=metadata_only full=y include=table
**** Excluding Objects from Import
- e.g.:exclude=trigger:"like 'B%'"
  - ??: why there is no backslash for single quote symbol
**** Including Objects from Import
- e.g.:include=table:"like 'A%'"
*** Common Data Pump Tasks
**** Estimating the Size of Export Jobs
- keyword: estimate_only
  - usage: estimate_only=y
**** Listing the Contents of Dump Files
**** Cloning a User
**** Creating a Consistent Export
**** Importing When Objects Already Exist
**** Renaming a Table
**** Remapping Data
**** Suppressing a Log File
**** Using Parallelism
**** Specifying Additional Dump File
**** Reusing Output File Names
**** Creating a Daily DDL File
**** Compressing Output
**** Changing Table Compression Characteristics on Import
**** Encrypt Data
**** Exporting Views As Tables
**** Disabling Logging of Redo on Import
*** Interactive Command Mode
**** Entering Interactive Command Mode
***** Ctrl+C
***** ATTACH
- determine the job name
  - select owner, operation,job_name,state from dba_datapump_jobs
- attach the job you want to attach
  - if you are the job owner: expdp mv_maint/foo attach=<job_name>
  - if you are not the owner: expdp system/foobar attach=<job_owner>.<job_name>
**** Stopping and Restarting a Job
sometimes you want to stop a job temporarily and solve some problems and then continue the job
- attach a job
  - e.g.: impdp mv_maint/foo attach=sys_import_table_01
- stop a job
  - e.g.: stop_job
  - e.g.: stop_job=immediate
- start a job
  - start_job
**** Terminating a Data Pump Job
- attach to the job in interactive mode
- run kill_job command
*** Monitoring Data Pump Jobs
**** Data Pump Log File
**** Data Dictionary Views
**** Database Alert Log
**** Status Table
**** Interactive Command Mode Status
**** OS Utilities
*** Data Pump Legacy Mode
*** Summary
